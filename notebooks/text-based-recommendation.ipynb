{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, RobertaModel, RobertaConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "BertLayerNorm = torch.nn.LayerNorm\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures\n",
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, Optional, List, Union\n",
    "from enum import Enum\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EvalPrediction, PreTrainedTokenizer\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualRobertaForDotProduct(PreTrainedModel):\n",
    "    config_class = RobertaConfig\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size*2, config.hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.hidden_size//2, 1),\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        user_input_ids=None,\n",
    "        user_attention_mask=None,\n",
    "        user_token_type_ids=None,\n",
    "        user_position_ids=None,\n",
    "        user_head_mask=None,\n",
    "        user_inputs_embeds=None,\n",
    "        user_output_attentions=None,\n",
    "        user_output_hidden_states=None,\n",
    "        user_return_dict=None,\n",
    "        item_input_ids=None,\n",
    "        item_attention_mask=None,\n",
    "        item_token_type_ids=None,\n",
    "        item_position_ids=None,\n",
    "        item_head_mask=None,\n",
    "        item_inputs_embeds=None,\n",
    "        labels=None,\n",
    "        item_output_attentions=None,\n",
    "        item_output_hidden_states=None,\n",
    "        item_return_dict=None,\n",
    "    ):\n",
    "        user_outputs = self.roberta(\n",
    "            user_input_ids,\n",
    "            attention_mask=user_attention_mask,\n",
    "            token_type_ids=user_token_type_ids,\n",
    "            position_ids=user_position_ids,\n",
    "            head_mask=user_head_mask,\n",
    "            inputs_embeds=user_inputs_embeds,\n",
    "            output_attentions=user_output_attentions,\n",
    "            output_hidden_states=user_output_hidden_states,\n",
    "        )\n",
    "        item_outputs = self.roberta(\n",
    "            item_input_ids,\n",
    "            attention_mask=item_attention_mask,\n",
    "            token_type_ids=item_token_type_ids,\n",
    "            position_ids=item_position_ids,\n",
    "            head_mask=item_head_mask,\n",
    "            inputs_embeds=item_inputs_embeds,\n",
    "            output_attentions=item_output_attentions,\n",
    "            output_hidden_states=item_output_hidden_states,\n",
    "        )\n",
    "\n",
    "        user_rep = user_outputs[1]\n",
    "        item_rep = item_outputs[1]\n",
    "        # score = torch.sum(user_rep * item_rep, -1)\n",
    "        score = self.fc(torch.cat([user_rep, item_rep], -1)).view(-1)\n",
    "\n",
    "        # code.interact(local=locals())\n",
    "        loss = torch.nn.functional.mse_loss(score, labels.float(), reduction=\"mean\")\n",
    "        reg = torch.sum(user_rep*user_rep, -1).mean() + torch.sum(item_rep*item_rep, -1).mean()\n",
    "        loss = loss + reg\n",
    "\n",
    "        # code.interact(local=locals())\n",
    "\n",
    "        return (loss, score)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        elif isinstance(module, BertLayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 创建一个加载Recommendation dataset数据集的库\n",
    "\"\"\"\n",
    "class RecProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the Recommendation data set (GLUE version).\"\"\"\n",
    "\n",
    "    def __init__(self, user_reviews_file, item_reviews_file):\n",
    "        self.user_reviews = {}\n",
    "        self.item_reviews = {}\n",
    "        with open(user_reviews_file) as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                self.user_reviews[line[0]] = line[1:]\n",
    "        with open(item_reviews_file) as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                self.item_reviews[line[0]] = line[1:]\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(os.path.join(data_dir, \"train.csv\"), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(os.path.join(data_dir, \"valid.csv\"), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(os.path.join(data_dir, \"test.csv\"), \"test\")\n",
    "\n",
    "    def _create_examples(self, filename, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "\n",
    "        data = pd.read_csv(filename)\n",
    "        user_review_examples = []\n",
    "        item_review_examples = []\n",
    "        for i in range(data.shape[0]):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            row = data.iloc[i]\n",
    "            user_id = str(row[\"user_id\"])\n",
    "            item_id = str(row[\"item_id\"])\n",
    "            label = float(row[\"ratings\"])\n",
    "            rating = row[\"ratings\"]\n",
    "            user_reviews = self.user_reviews[user_id] if user_id in self.user_reviews else [\"N/A\"]\n",
    "            item_reviews = self.item_reviews[item_id] if item_id in self.user_reviews else [\"N/A\"]\n",
    "            random.shuffle(user_reviews)\n",
    "            random.shuffle(item_reviews)\n",
    "            user_reviews = \" [SEP] \".join(user_reviews)\n",
    "            item_reviews = \" [SEP] \".join(item_reviews)\n",
    "            user_review_examples.append(InputExample(guid=guid, text_a=user_reviews, label=label))\n",
    "            item_review_examples.append(InputExample(guid=guid, text_a=item_reviews, label=label))\n",
    "\n",
    "        return user_review_examples, item_review_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    Using `HfArgumentParser` we can turn this class\n",
    "    into argparse arguments to be able to specify them on\n",
    "    the command line.\n",
    "    \"\"\"\n",
    "\n",
    "    task_name: str = field(metadata={\"help\": \"The name of the task to train on\"})\n",
    "    data_dir: str = field(\n",
    "        metadata={\"help\": \"The input data dir. Should contain the .txt files (or other data files) for the task.\"}\n",
    "    )\n",
    "    user_reviews_file: str = field(\n",
    "        metadata={\"help\": \"The file containing all user reviews\"}\n",
    "    )\n",
    "    item_reviews_file: str = field(\n",
    "        metadata={\"help\": \"The file containing all item reviews\"}\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.task_name = self.task_name.lower()\n",
    "        \n",
    "class Split(Enum):\n",
    "    train = \"train\"\n",
    "    dev = \"dev\"\n",
    "    test = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 在这个function中，我们会把文本数据转化为可以传入BERT模型的index, mask等输入\n",
    "\"\"\"\n",
    "def convert_examples_to_features(\n",
    "    examples: List[InputExample],\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    max_length: Optional[int] = None,\n",
    "    task=None,\n",
    "    output_mode=None,\n",
    "):\n",
    "    if max_length is None:\n",
    "        max_length = tokenizer.max_len\n",
    "\n",
    "    batch_encoding = tokenizer(\n",
    "        [example.text_a for example in examples],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(examples)):\n",
    "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "\n",
    "        # https://github.com/huggingface/transformers/blob/master/src/transformers/data/processors/utils.py#L56\n",
    "        # InputFeatures当中包含了input_ids, attention_mask, token_type_ids和label四个部分\n",
    "        # feature = InputFeatures(**inputs)\n",
    "        features.append(inputs)\n",
    "\n",
    "    for i, example in enumerate(examples[:5]):\n",
    "        logger.info(\"*** Example ***\")\n",
    "        logger.info(\"guid: %s\" % (example.guid))\n",
    "        logger.info(\"features: %s\" % features[i])\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" RecDataset这个库继承了PyTorch自带的Dataset库。转换成dataloader之后可以用来做训练和测试\n",
    "\"\"\"\n",
    "class RecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This will be superseded by a framework-agnostic approach\n",
    "    soon.\n",
    "    \"\"\"\n",
    "\n",
    "    args: DataTrainingArguments\n",
    "    output_mode: str\n",
    "    features: List[InputFeatures]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args: DataTrainingArguments,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        limit_length: Optional[int] = None,\n",
    "        mode: Union[str, Split] = Split.train,\n",
    "        cache_dir: Optional[str] = None,\n",
    "    ):\n",
    "        self.args = args\n",
    "        self.processor = RecProcessor(args.user_reviews_file, args.item_reviews_file)\n",
    "        if isinstance(mode, str):\n",
    "            try:\n",
    "                mode = Split[mode]\n",
    "            except KeyError:\n",
    "                raise KeyError(\"mode is not a valid split name\")\n",
    "        # Load data features from cache or dataset file\n",
    "\n",
    "        # Make sure only the first process in distributed training processes the dataset,\n",
    "        # and the others will use the cache.\n",
    "\n",
    "        logger.info(f\"Creating features from dataset file at {args.data_dir}\")\n",
    "\n",
    "        if mode == Split.dev:\n",
    "            user_review_examples, item_review_examples = self.processor.get_dev_examples(args.data_dir)\n",
    "            pickle_path = os.path.join(args.data_dir, \"features.dev.pkl\")\n",
    "        elif mode == Split.test:\n",
    "            user_review_examples, item_review_examples = self.processor.get_test_examples(args.data_dir)\n",
    "            pickle_path = os.path.join(args.data_dir, \"features.test.pkl\")\n",
    "        else:\n",
    "            user_review_examples, item_review_examples = self.processor.get_train_examples(args.data_dir)\n",
    "            pickle_path = os.path.join(args.data_dir, \"features.train.pkl\")\n",
    "\n",
    "        if os.path.exists(pickle_path):\n",
    "            logger.info(\"*** Loading features from the pickle file ***\")\n",
    "            self.user_review_features, self.item_review_features = pickle.load(open(pickle_path, \"rb\"))\n",
    "        else:\n",
    "            logger.info(\"*** Creating the feature pickle file ***\")\n",
    "            self.user_review_features = convert_examples_to_features(\n",
    "                user_review_examples,\n",
    "                tokenizer,\n",
    "                max_length=args.max_seq_length,\n",
    "            )\n",
    "            self.item_review_features = convert_examples_to_features(\n",
    "                item_review_examples,\n",
    "                tokenizer,\n",
    "                max_length=args.max_seq_length,\n",
    "            )\n",
    "            pickle.dump([self.user_review_features, self.item_review_features], open(pickle_path, \"wb\"))\n",
    "\n",
    "\n",
    "\n",
    "        assert len(self.user_review_features) == len(self.item_review_features)\n",
    "\n",
    "        self.features = []\n",
    "        for i in range(len(self.user_review_features)):\n",
    "            feature = {}\n",
    "            for k, v in self.user_review_features[i].items():\n",
    "                feature[\"user_\" + k] = v\n",
    "            for k, v in self.item_review_features[i].items():\n",
    "                feature[\"item_\" + k] = v\n",
    "            feature[\"labels\"] = user_review_examples[i].label\n",
    "            self.features.append(feature)\n",
    "\n",
    "        # code.interact(local=locals())\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i]\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "DATA_DIR = \"data\"\n",
    "arguments = {\n",
    "    \"model_name_or_path\": \"roberta-base\",\n",
    "    \"task_name\": \"Rec\",\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_predict\": True,\n",
    "    \"item_reviews_file\": os.path.join(DATA_DIR, \"item_review.tsv\"), \n",
    "    \"user_reviews_file\": os.path.join(DATA_DIR, \"user_review.tsv\"), \n",
    "    \"data_dir\": DATA_DIR,\n",
    "    \"max_seq_length\": 128,\n",
    "    \"per_device_train_batch_size\": 32, \n",
    "    \"learning_rate\": 2e-5, \n",
    "    \"num_train_epochs\": 3.0, \n",
    "    \"output_dir\": \"./saved_checkpoints_\" + DATA_DIR\n",
    "}\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "\n",
    "model_args, data_args, training_args = parser.parse_json_file(json_file=\"hyperparams.json\")\n",
    "\n",
    "if (\n",
    "    os.path.exists(training_args.output_dir)\n",
    "    and os.listdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    raise ValueError(\n",
    "        f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
    "    )\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.local_rank,\n",
    "    training_args.device,\n",
    "    training_args.n_gpu,\n",
    "    bool(training_args.local_rank != -1),\n",
    "    training_args.fp16,\n",
    ")\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "\n",
    "# Set seed\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "output_mode = \"regression\"\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "#\n",
    "# Distributed training:\n",
    "# The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab.\n",
    "\n",
    "# tokenizer，用来做分词等数据预处理工作\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "train_dataset = RecDataset(data_args, tokenizer=tokenizer, cache_dir=model_args.cache_dir)\n",
    "# num_labels = len(train_dataset.get_labels())\n",
    "\n",
    "# config 包含了模型的基本参数设定\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    finetuning_task=data_args.task_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_args.model_name_or_path,\n",
    "#     from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "#     config=config,\n",
    "#     cache_dir=model_args.cache_dir,\n",
    "# ) #.cuda()\n",
    "model = DualRobertaForDotProduct.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "\n",
    "# Get datasets\n",
    "eval_dataset = (\n",
    "    RecDataset(data_args, tokenizer=tokenizer, mode=\"dev\", cache_dir=model_args.cache_dir)\n",
    "    if training_args.do_eval\n",
    "    else None\n",
    ")\n",
    "test_dataset = (\n",
    "    RecDataset(data_args, tokenizer=tokenizer, mode=\"test\", cache_dir=model_args.cache_dir)\n",
    "    if training_args.do_predict\n",
    "    else None\n",
    ")\n",
    "\n",
    "def mse(preds, labels):\n",
    "    return ((preds - labels)*(preds - labels)).mean()\n",
    "\n",
    "def compute_metrics_fn(p: EvalPrediction):\n",
    "    preds = p.predictions\n",
    "    return {\"Rec\": mse(preds, p.label_ids)}\n",
    "\n",
    "\n",
    "# Initialize our Trainer\n",
    "# 模型训练代码，非常值得一读 https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py#L134\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics_fn,\n",
    ")\n",
    "\n",
    "\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    trainer.train(\n",
    "        model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
    "    )\n",
    "    trainer.save_model()\n",
    "    # For convenience, we also re-save the tokenizer to the same directory,\n",
    "    # so that you can share your model easily on huggingface.co/models =)\n",
    "    if trainer.is_world_master():\n",
    "        tokenizer.save_pretrained(training_args.output_dir)\n",
    "\n",
    "# Evaluation\n",
    "eval_results = {}\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_datasets = [eval_dataset]\n",
    "\n",
    "    for eval_dataset in eval_datasets:\n",
    "        trainer.compute_metrics = compute_metrics_fn\n",
    "        eval_result = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "        output_eval_file = os.path.join(\n",
    "            training_args.output_dir, f\"eval_results_{eval_dataset.args.task_name}.txt\"\n",
    "        )\n",
    "        if trainer.is_world_master():\n",
    "            with open(output_eval_file, \"w\") as writer:\n",
    "                logger.info(\"***** Eval results {} *****\".format(eval_dataset.args.task_name))\n",
    "                for key, value in eval_result.items():\n",
    "                    logger.info(\"  %s = %s\", key, value)\n",
    "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
    "\n",
    "        eval_results.update(eval_result)\n",
    "\n",
    "if training_args.do_predict:\n",
    "    logging.info(\"*** Test ***\")\n",
    "    test_datasets = [test_dataset]\n",
    "\n",
    "    for test_dataset in test_datasets:\n",
    "        predictions = trainer.predict(test_dataset=test_dataset).predictions\n",
    "\n",
    "        output_test_file = os.path.join(\n",
    "            training_args.output_dir, f\"test_results_{test_dataset.args.task_name}.txt\"\n",
    "        )\n",
    "        if trainer.is_world_master():\n",
    "            with open(output_test_file, \"w\") as writer:\n",
    "                logger.info(\"***** Test results {} *****\".format(test_dataset.args.task_name))\n",
    "                writer.write(\"index\\tprediction\\n\")\n",
    "                for index, item in enumerate(predictions):\n",
    "                    writer.write(\"%d\\t%3.3f\\n\" % (index, item))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
